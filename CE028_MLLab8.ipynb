{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmV2jT3xrHKqMCTQh21iqW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stacking"
      ],
      "metadata": {
        "id": "pVFdEV2xgKaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(data.data, data.target, random_state=97, train_size=0.6)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, random_state=97, test_size=0.3)\n",
        "\n",
        "print(data.data.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjejbDkDgMun",
        "outputId": "5d36f05d-4292-49f2-b9b5-4d7d0861821b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWZbYpTnf6rc",
        "outputId": "f9be6fca-d8e3-47ec-aaa0-a08e692e203b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17070\n"
          ]
        }
      ],
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(data.data, data.target, random_state=97, train_size=0.6)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, random_state=97, test_size=0.3)\n",
        "\n",
        "print(data.data.size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "models = dict()\n",
        "# preds = list()\n",
        "models['lr'] = LogisticRegression(max_iter=100000)\n",
        "models['cart'] = DecisionTreeClassifier()\n",
        "models['bayes'] = GaussianNB()\n",
        "\n",
        "\n",
        "\n",
        "for model in models:\n",
        "  models[model].fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "5mvWGCCLgFkx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = models['lr'].predict(X_valid)\n",
        "pred2 = models['cart'].predict(X_valid)\n",
        "pred3 = models['bayes'].predict(X_valid)\n",
        "\n",
        "test_preds1 = models['lr'].predict(X_test)\n",
        "test_preds2 = models['cart'].predict(X_test)\n",
        "test_preds3 = models['bayes'].predict(X_test)\n",
        "\n",
        "data_df_new = pd.DataFrame(data = X_valid,\n",
        "                       columns = data.feature_names)\n",
        "data_df_new['lr'] = pred1\n",
        "data_df_new['cart'] = pred2\n",
        "data_df_new['bayes'] = pred3\n",
        "\n",
        "\n",
        "print(data_df_new.info())\n",
        "print(data_df_new.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sggkx1UgPBP",
        "outputId": "e5688310-c58b-4625-9ae1-512be16508f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159 entries, 0 to 158\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              159 non-null    float64\n",
            " 1   mean texture             159 non-null    float64\n",
            " 2   mean perimeter           159 non-null    float64\n",
            " 3   mean area                159 non-null    float64\n",
            " 4   mean smoothness          159 non-null    float64\n",
            " 5   mean compactness         159 non-null    float64\n",
            " 6   mean concavity           159 non-null    float64\n",
            " 7   mean concave points      159 non-null    float64\n",
            " 8   mean symmetry            159 non-null    float64\n",
            " 9   mean fractal dimension   159 non-null    float64\n",
            " 10  radius error             159 non-null    float64\n",
            " 11  texture error            159 non-null    float64\n",
            " 12  perimeter error          159 non-null    float64\n",
            " 13  area error               159 non-null    float64\n",
            " 14  smoothness error         159 non-null    float64\n",
            " 15  compactness error        159 non-null    float64\n",
            " 16  concavity error          159 non-null    float64\n",
            " 17  concave points error     159 non-null    float64\n",
            " 18  symmetry error           159 non-null    float64\n",
            " 19  fractal dimension error  159 non-null    float64\n",
            " 20  worst radius             159 non-null    float64\n",
            " 21  worst texture            159 non-null    float64\n",
            " 22  worst perimeter          159 non-null    float64\n",
            " 23  worst area               159 non-null    float64\n",
            " 24  worst smoothness         159 non-null    float64\n",
            " 25  worst compactness        159 non-null    float64\n",
            " 26  worst concavity          159 non-null    float64\n",
            " 27  worst concave points     159 non-null    float64\n",
            " 28  worst symmetry           159 non-null    float64\n",
            " 29  worst fractal dimension  159 non-null    float64\n",
            " 30  lr                       159 non-null    int64  \n",
            " 31  cart                     159 non-null    int64  \n",
            " 32  bayes                    159 non-null    int64  \n",
            "dtypes: float64(30), int64(3)\n",
            "memory usage: 41.1 KB\n",
            "None\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0       13.050         13.84           82.71      530.6          0.08352   \n",
            "1       10.180         17.53           65.12      313.1          0.10610   \n",
            "2       12.630         20.76           82.15      480.4          0.09933   \n",
            "3        9.405         21.70           59.60      271.2          0.10440   \n",
            "4       11.410         14.92           73.53      402.0          0.09059   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.03735        0.004559             0.008829         0.1453   \n",
            "1           0.08502        0.017680             0.019150         0.1910   \n",
            "2           0.12090        0.106500             0.060210         0.1735   \n",
            "3           0.06159        0.020470             0.012570         0.2025   \n",
            "4           0.08155        0.061810             0.023610         0.1167   \n",
            "\n",
            "   mean fractal dimension  ...  worst area  worst smoothness  \\\n",
            "0                 0.05518  ...       672.4            0.1016   \n",
            "1                 0.06908  ...       375.6            0.1406   \n",
            "2                 0.07070  ...       527.4            0.1287   \n",
            "3                 0.06601  ...       359.4            0.1526   \n",
            "4                 0.06217  ...       467.2            0.1121   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0            0.05847          0.01824               0.03532          0.2107   \n",
            "1            0.14400          0.06572               0.05575          0.3055   \n",
            "2            0.22500          0.22160               0.11050          0.2226   \n",
            "3            0.11930          0.06141               0.03770          0.2872   \n",
            "4            0.16100          0.16480               0.06296          0.1811   \n",
            "\n",
            "   worst fractal dimension  lr  cart  bayes  \n",
            "0                  0.06580   1     1      1  \n",
            "1                  0.08797   1     1      1  \n",
            "2                  0.08486   1     1      1  \n",
            "3                  0.08304   1     1      1  \n",
            "4                  0.07427   1     1      1  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = models['lr'].predict(X_valid)\n",
        "pred2 = models['cart'].predict(X_valid)\n",
        "pred3 = models['bayes'].predict(X_valid)\n",
        "\n",
        "test_preds1 = models['lr'].predict(X_test)\n",
        "test_preds2 = models['cart'].predict(X_test)\n",
        "test_preds3 = models['bayes'].predict(X_test)\n",
        "\n",
        "data_df_new = pd.DataFrame(data = X_valid,\n",
        "                       columns = data.feature_names)\n",
        "data_df_new['lr'] = pred1\n",
        "data_df_new['cart'] = pred2\n",
        "data_df_new['bayes'] = pred3\n",
        "\n",
        "\n",
        "print(data_df_new.info())\n",
        "print(data_df_new.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVD7HzkSgTts",
        "outputId": "2abc7395-d5a3-4178-c452-c0d3457658e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159 entries, 0 to 158\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              159 non-null    float64\n",
            " 1   mean texture             159 non-null    float64\n",
            " 2   mean perimeter           159 non-null    float64\n",
            " 3   mean area                159 non-null    float64\n",
            " 4   mean smoothness          159 non-null    float64\n",
            " 5   mean compactness         159 non-null    float64\n",
            " 6   mean concavity           159 non-null    float64\n",
            " 7   mean concave points      159 non-null    float64\n",
            " 8   mean symmetry            159 non-null    float64\n",
            " 9   mean fractal dimension   159 non-null    float64\n",
            " 10  radius error             159 non-null    float64\n",
            " 11  texture error            159 non-null    float64\n",
            " 12  perimeter error          159 non-null    float64\n",
            " 13  area error               159 non-null    float64\n",
            " 14  smoothness error         159 non-null    float64\n",
            " 15  compactness error        159 non-null    float64\n",
            " 16  concavity error          159 non-null    float64\n",
            " 17  concave points error     159 non-null    float64\n",
            " 18  symmetry error           159 non-null    float64\n",
            " 19  fractal dimension error  159 non-null    float64\n",
            " 20  worst radius             159 non-null    float64\n",
            " 21  worst texture            159 non-null    float64\n",
            " 22  worst perimeter          159 non-null    float64\n",
            " 23  worst area               159 non-null    float64\n",
            " 24  worst smoothness         159 non-null    float64\n",
            " 25  worst compactness        159 non-null    float64\n",
            " 26  worst concavity          159 non-null    float64\n",
            " 27  worst concave points     159 non-null    float64\n",
            " 28  worst symmetry           159 non-null    float64\n",
            " 29  worst fractal dimension  159 non-null    float64\n",
            " 30  lr                       159 non-null    int64  \n",
            " 31  cart                     159 non-null    int64  \n",
            " 32  bayes                    159 non-null    int64  \n",
            "dtypes: float64(30), int64(3)\n",
            "memory usage: 41.1 KB\n",
            "None\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0       13.050         13.84           82.71      530.6          0.08352   \n",
            "1       10.180         17.53           65.12      313.1          0.10610   \n",
            "2       12.630         20.76           82.15      480.4          0.09933   \n",
            "3        9.405         21.70           59.60      271.2          0.10440   \n",
            "4       11.410         14.92           73.53      402.0          0.09059   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.03735        0.004559             0.008829         0.1453   \n",
            "1           0.08502        0.017680             0.019150         0.1910   \n",
            "2           0.12090        0.106500             0.060210         0.1735   \n",
            "3           0.06159        0.020470             0.012570         0.2025   \n",
            "4           0.08155        0.061810             0.023610         0.1167   \n",
            "\n",
            "   mean fractal dimension  ...  worst area  worst smoothness  \\\n",
            "0                 0.05518  ...       672.4            0.1016   \n",
            "1                 0.06908  ...       375.6            0.1406   \n",
            "2                 0.07070  ...       527.4            0.1287   \n",
            "3                 0.06601  ...       359.4            0.1526   \n",
            "4                 0.06217  ...       467.2            0.1121   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0            0.05847          0.01824               0.03532          0.2107   \n",
            "1            0.14400          0.06572               0.05575          0.3055   \n",
            "2            0.22500          0.22160               0.11050          0.2226   \n",
            "3            0.11930          0.06141               0.03770          0.2872   \n",
            "4            0.16100          0.16480               0.06296          0.1811   \n",
            "\n",
            "   worst fractal dimension  lr  cart  bayes  \n",
            "0                  0.06580   1     1      1  \n",
            "1                  0.08797   1     1      1  \n",
            "2                  0.08486   1     1      1  \n",
            "3                  0.08304   1     1      1  \n",
            "4                  0.07427   1     1      1  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmyQOwk_gXla",
        "outputId": "e3e7b4d0-77ab-4a35-d1c2-09414babb2fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_stack = np.column_stack((pred1,pred2,pred3))\n",
        "test_stack = np.column_stack((test_preds1,test_preds2,test_preds3))"
      ],
      "metadata": {
        "id": "UsZJsXNXga7E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = LogisticRegression(max_iter=100000)\n",
        "\n",
        "final_model.fit(train_stack,y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m2z6jFNgeVh",
        "outputId": "2e9440a7-d79f-4e2b-eef8-d51bf3b30050"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=100000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = final_model.predict(test_stack)"
      ],
      "metadata": {
        "id": "FJi9Ob43ggyI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy: \",metrics.accuracy_score(y_test, final_predictions))\n",
        "print(\"Precision: \",metrics.precision_score(y_test, final_predictions))\n",
        "print(\"Recall: \",metrics.recall_score(y_test, final_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2dD6R_FgitY",
        "outputId": "4d890778-0b5f-4082-fb07-d623c26c69d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9855072463768116\n",
            "Precision:  0.9791666666666666\n",
            "Recall:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def model_Evaluate(model, y_test, final_predictions):\n",
        "  print(classification_report(y_test, final_predictions))\n",
        "\n",
        "\n",
        "model_Evaluate(final_model, y_test, final_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPcWD9CAgkkq",
        "outputId": "b1df4f84-22b9-4751-d4e3-4d4f093a0863"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        22\n",
            "           1       0.98      1.00      0.99        47\n",
            "\n",
            "    accuracy                           0.99        69\n",
            "   macro avg       0.99      0.98      0.98        69\n",
            "weighted avg       0.99      0.99      0.99        69\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "StackingClassifier from sklearn"
      ],
      "metadata": {
        "id": "GeBYO6WWglL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "data=load_breast_cancer()\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=97, train_size=0.8)\n",
        "\n",
        "\n",
        "model1 = LogisticRegression(max_iter=100000)\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = GaussianNB()\n",
        "\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6cne7AogoGQ",
        "outputId": "14a09d83-973c-44f9-a70a-1e7b1fd8b5ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 0 0 0\n",
            " 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0\n",
            " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 0\n",
            " 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "     ('lr', model1),\n",
        "     ('cart', model2),\n",
        "     ('bayes', model3)\n",
        "]\n",
        "\n",
        "final_model = LogisticRegression(max_iter=100000)\n",
        "sclf = StackingClassifier(estimators=estimators,\n",
        "                            final_estimator=final_model,\n",
        "                            cv=10)"
      ],
      "metadata": {
        "id": "myHV0mSpgrzU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sclf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Cy0K-8PgwTO",
        "outputId": "cba1ae77-5c12-47c6-9227-8a14c0873712"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=10,\n",
              "                   estimators=[('lr', LogisticRegression(max_iter=100000)),\n",
              "                               ('cart', DecisionTreeClassifier()),\n",
              "                               ('bayes', GaussianNB())],\n",
              "                   final_estimator=LogisticRegression(max_iter=100000))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = sclf.predict(X_test)"
      ],
      "metadata": {
        "id": "oF4MGH02gx4S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \",sclf.score(X_test, y_test))\n",
        "print(\"Precision: \",metrics.precision_score( y_test, prediction))\n",
        "print(\"Accuracy: \",metrics.recall_score( y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zvh2Rhfg0GC",
        "outputId": "20b9ebf9-00ee-4773-9cc9-5d74ced9b7e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.956140350877193\n",
            "Precision:  0.9558823529411765\n",
            "Accuracy:  0.9701492537313433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost"
      ],
      "metadata": {
        "id": "5dvYY8Vwg1kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "data=load_breast_cancer()\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=97, train_size=0.8)\n",
        "\n",
        "\n",
        "model1 = LogisticRegression(max_iter=100000)\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = GaussianNB()\n",
        "\n",
        "estimators = [\n",
        "     ('lr', model1),\n",
        "     ('cart', model2),\n",
        "     ('bayes', model3)\n",
        "]"
      ],
      "metadata": {
        "id": "cOktWcKsg1NK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = AdaBoostClassifier(learning_rate=1)\n",
        "abc.fit(X_train, y_train)\n",
        "\n",
        "prediction = abc.predict(X_test)"
      ],
      "metadata": {
        "id": "XKLqMYCxg608"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy: \",abc.score(X_test, y_test))\n",
        "print(\"Precision: \",metrics.precision_score(y_test, prediction))\n",
        "print(\"Recall: \",metrics.recall_score( y_test, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoisV80Ug9dy",
        "outputId": "19242eab-338e-4d69-eb7e-8b5b3cf7c82b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9473684210526315\n",
            "Precision:  0.9552238805970149\n",
            "Recall:  0.9552238805970149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost Regression on concrete_data.csv"
      ],
      "metadata": {
        "id": "jtg12MY0hBKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV51hw_1hAH9",
        "outputId": "f2b2d5a9-dffa-48b8-ca5e-6ac65c9723d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = pd.read_csv('/content/drive/MyDrive/datasets/Contrete.csv')"
      ],
      "metadata": {
        "id": "JytiD92chQxh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = datasets.iloc[:, :-1].values\n",
        "\n",
        "# Only last column, 0 for 1st column and -1 for last colum,-2 for 2nd last column\n",
        "y = datasets.iloc[:, -1].values\n",
        "print(\"\\n\\nInput : \\n\", X)\n",
        "print(\"\\n\\nOutput: \\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnBOXFwhhSzm",
        "outputId": "49990c5c-a4c3-4340-a778-684e7e73b12a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Input : \n",
            " [[ 540.     0.     0.  ... 1040.   676.    28. ]\n",
            " [ 540.     0.     0.  ... 1055.   676.    28. ]\n",
            " [ 332.5  142.5    0.  ...  932.   594.   270. ]\n",
            " ...\n",
            " [ 148.5  139.4  108.6 ...  892.4  780.    28. ]\n",
            " [ 159.1  186.7    0.  ...  989.6  788.9   28. ]\n",
            " [ 260.9  100.5   78.3 ...  864.5  761.5   28. ]]\n",
            "\n",
            "\n",
            "Output: \n",
            " [79.99 61.89 40.27 ... 23.7  32.77 32.4 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split data set into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasets, y, test_size = 0.25, random_state = 97)\n",
        "\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgl-Voy9hWVC",
        "outputId": "878fa55a-c0f4-49c8-a808-59d1a390d135"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22.72 13.57 51.02 25.22 21.78 35.76 36.35 33.08 55.06 37.96 56.83 39.36\n",
            " 25.69 66.82 67.11 23.51 14.6  61.09 65.91 76.24 21.95 33.06 55.02 17.22\n",
            " 50.53 57.03 11.41 39.38 17.95 25.73 51.72 15.61 21.97 24.24 69.3  35.57\n",
            " 28.94 64.3   6.28 28.02 79.4  77.3  55.6  15.34 59.09 72.99 70.7  42.8\n",
            " 45.08 66.   40.56 55.51 58.52 33.76 29.41 61.99 31.45 31.35 30.22  8.\n",
            " 53.69 53.9  53.52 12.47 13.09 32.84 36.45 44.09 32.53 52.83 42.29 35.08\n",
            " 17.44  9.73 42.22 14.99 40.27 74.36 34.9  74.19 17.6  23.8  10.54 14.2\n",
            " 18.2  15.42 39.   26.92 41.05 32.24 41.67 26.85 39.42 37.81 24.28 12.55\n",
            " 42.55 33.4  15.53 31.35 39.64 29.73 37.34 25.1  19.77 54.38 10.39 53.3\n",
            " 12.45 41.24 52.44 22.9  17.54 12.64 37.68 44.52 52.04 32.01 26.26 40.2\n",
            " 33.76 31.18 44.4  33.61  7.75 59.   52.12 50.73 46.9  32.63 43.38 56.74\n",
            " 32.05 40.87 51.73 22.44 64.9  41.68  6.27 21.48 12.05 41.16 43.38 24.43\n",
            " 17.84 10.35 48.79 66.9  33.73  7.84 66.7  13.46 52.52 11.65 14.4  44.87\n",
            " 18.42 19.69 64.9  39.29 13.12 55.94 14.59 38.11 49.8  55.64 74.7  25.56\n",
            " 15.04 43.57 21.06 56.4  67.8   7.68 60.29 24.   50.95 22.49 15.52 64.3\n",
            " 38.2  30.08 43.7  52.42 47.03 42.35 49.2  38.63 22.63 58.8  38.07 48.99\n",
            " 26.2  11.36 54.77 33.96 52.3   7.32 23.25 39.44 71.62 19.54 23.79 35.3\n",
            " 23.64 41.54 73.7  43.7  47.22 41.05  6.94 37.92 21.91 25.51 55.16  8.06\n",
            " 36.84 32.25 37.91 36.97 17.96 21.18 30.39 45.85 27.92 36.94 52.96 36.15\n",
            " 48.28 40.87 18.75 41.64 35.1  37.72 66.42 25.02 29.93 47.28 15.58 49.77\n",
            " 11.96 33.01 24.1  40.93 27.42 37.23 33.3  23.52 25.75 19.01  6.47 55.26\n",
            " 49.2  48.15 31.81 32.72 25.1  30.14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        " \n",
        "#Choosing Decision Tree with 1 level as the weak learner\n",
        "DTR=DecisionTreeRegressor(max_depth=1)\n",
        "RegModel = AdaBoostRegressor(n_estimators=50, base_estimator=DTR ,learning_rate=1)"
      ],
      "metadata": {
        "id": "OvH0kFwxhYPK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AB=RegModel.fit(X_train,y_train)\n",
        "y_pred=AB.predict(X_test)"
      ],
      "metadata": {
        "id": "Ew9-36cqhZ4G"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# model_Evaluate(AB, y_test, predictions) --> doesn't work for continuous values\n",
        "print(\"Accuracy: \",RegModel.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stGU8iLMhbm-",
        "outputId": "91203fb2-f675-4dd5-bb6d-da76dbd66bfe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7057686422041147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X,y = load_diabetes(return_X_y=True)\n",
        "\n",
        "#split data set into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 97)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        " \n",
        "#Choosing Decision Tree with 1 level as the weak learner\n",
        "DTR=DecisionTreeRegressor(max_depth=10)\n",
        "RegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=1)\n",
        "\n",
        "AB=RegModel.fit(X_train,y_train)\n",
        "y_pred=AB.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# model_Evaluate(AB, y_test, predictions) --> doesn't work for continuous values\n",
        "print(\"Accuracy: \",RegModel.score(X_test, y_test))\n",
        "\n",
        "print(\"Mean Square Error: \",mean_squared_error(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPtWxGzxheqx",
        "outputId": "004960f2-4832-4fc4-9e96-9d79b6ee56a8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.38678549468167767\n",
            "Mean Square Error:  3942.5735170757184\n"
          ]
        }
      ]
    }
  ]
}